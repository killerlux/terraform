# ğŸ–¥ï¸ Server Status & Information

## ğŸ“¡ **Current Active Server**

- **IP Address**: `159.89.100.120`
- **Region**: Amsterdam (AMS3)
- **Server Type**: s-2vcpu-4gb (2 vCPUs, 4GB RAM, 80GB SSD)
- **Deployment Date**: December 2024
- **Cost**: ~$24/month

## ğŸš€ **Services Status**

### **ğŸ“Š n8n Workflow Platform**
- **URL**: http://159.89.100.120:5678
- **Status**: âœ… Operational
- **Health Check**: `curl http://159.89.100.120:5678/healthz`
- **Purpose**: Workflow orchestration and web interface

### **ğŸ¤– Ollama LLM Engine**
- **URL**: http://159.89.100.120:11434
- **Status**: â³ Starting (downloading Llama3 model)
- **Health Check**: `curl http://159.89.100.120:11434/api/tags`
- **Model**: Llama3 8B (~4.7GB download)

### **ğŸ§  ChromaDB Vector Database**
- **URL**: http://159.89.100.120:8000
- **Status**: â³ Starting
- **Health Check**: `curl http://159.89.100.120:8000/api/v1/heartbeat`
- **Purpose**: Vector embeddings storage and similarity search

## ğŸ”§ **Quick Access Commands**

### **Check All Services**
```bash
# Quick health check
curl -s http://159.89.100.120:5678/healthz  # n8n
curl -s http://159.89.100.120:11434/api/tags # Ollama models
curl -s http://159.89.100.120:8000/api/v1/heartbeat # ChromaDB
```

### **SSH Access**
```bash
# Connect to server
ssh -i ~/.ssh/private-ai root@159.89.100.120

# Check Docker services
docker compose ps

# View logs
docker compose logs -f n8n
docker compose logs -f ollama
docker compose logs -f chroma
```

## ğŸ“ˆ **Performance Monitoring**

### **Resource Usage**
```bash
# Check server resources
ssh root@159.89.100.120 "htop"
ssh root@159.89.100.120 "df -h"
ssh root@159.89.100.120 "free -h"
```

### **Docker Stats**
```bash
# Monitor container performance
ssh root@159.89.100.120 "docker stats --no-stream"
```

## ğŸ”„ **Service Management**

### **Restart Services**
```bash
# Restart all services
ssh root@159.89.100.120 "cd /root/private-ai && docker compose restart"

# Restart individual service
ssh root@159.89.100.120 "cd /root/private-ai && docker compose restart n8n"
```

### **Update Deployment**
Use GitHub Actions workflow dispatch with option `restart-services` to update without destroying the server.

## ğŸš¨ **Troubleshooting**

### **Common Issues**

| Issue | Solution | Command |
|-------|----------|---------|
| n8n not responding | Restart n8n container | `docker compose restart n8n` |
| Ollama model missing | Re-download model | `docker exec ollama_service ollama pull llama3:8b` |
| ChromaDB connection error | Check port 8000 | `netstat -tulpn | grep 8000` |
| Out of disk space | Clean Docker images | `docker system prune -a` |

### **Emergency Recovery**
If services are completely down:
```bash
ssh root@159.89.100.120
cd /root/private-ai
docker compose down
docker compose up -d
```

## ğŸ“Š **Service URLs for Bookmarks**

- **ğŸ›ï¸ n8n Interface**: http://159.89.100.120:5678
- **ğŸ“„ Document Upload**: http://159.89.100.120:5678/webhook/ingest-document
- **ğŸ’¬ Chat Interface**: http://159.89.100.120:5678/webhook/chat
- **ğŸ¤– Ollama API**: http://159.89.100.120:11434
- **ğŸ§  ChromaDB Dashboard**: http://159.89.100.120:8000

## ğŸ” **Security Notes**

- Server uses SSH key authentication only
- All services run on private Docker network
- Firewall configured for necessary ports only
- Regular security updates via GitHub Actions

---

**Last Updated**: December 2024
**Next Review**: Check monthly for updates and security patches 